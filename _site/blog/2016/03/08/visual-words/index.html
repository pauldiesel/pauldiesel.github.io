<!DOCTYPE HTML><html><head><meta charset="utf-8" /><link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/assets/img/apple-icon.png"><link rel="icon" type="image/png" href="http://localhost:4000/assets/img/favicon.png"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><title>Visual Word Representation</title><meta name="description" content="Do images speak?" /><meta name="author" content="M Reddy" /><meta name="viewport" content='width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0' /><meta name="keywords" content="visual-words,sift,image-processing,Arcane, Reveries, M" /><meta name="msvalidate.01" content="" /><!-- Fonts and icons --><link rel="canonical" href="http://localhost:4000/blog/2016/03/08/visual-words/" /><link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons" /><link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700" /><link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:400,700|Material+Icons" /><link rel="stylesheet" href="http://localhost:4000/assets/stylesheets/font-awesome.min.css" /><link href="https://fonts.googleapis.com/css?family=Comfortaa" rel="stylesheet"><!-- CSS Files --><link href="http://localhost:4000/assets/stylesheets/application.css" rel="stylesheet" /> <script>var siteUrl = "http://localhost:4000"; var pageUrl = "/blog/2016/03/08/visual-words/"</script><!-- Open Graph Meta Tags --><meta property="og:url" content="http://localhost:4000/blog/2016/03/08/visual-words/" /><meta property="og:type" content="article" /><meta property="og:title" content="Visual Word Representation" /><meta property="og:description" content="Do images speak?" /><meta property="og:image" content="http://localhost:4000/assets/img/blog.jpg" /><meta property="og:image:alt" content="Visual Word Representation" /><!-- Facebook Tags --><!-- Twitter Tags --><meta name="twitter:card" content="summary" /><meta name="twitter:creator" content="@" /><meta name="twitter:site" content="@" /><meta name="twitter:title" content="Visual Word Representation" /><meta name="twitter:description" content="Do images speak?" /><meta name="twitter:image" content="http://localhost:4000" /><!-- Google Data --> <script type="application/ld+json"> { "@context": "https://schema.org", "@type": "Article", "mainEntityOfPage": { "@type": "WebPage", "@id": "http://localhost:4000/blog/2016/03/08/visual-words/" }, "headline": "Visual Word Representation", "image": [ "http://localhost:4000" ], "datePublished": "2016-03-08 00:00:00 -0500", "publisher":{ "@type": "Organization", "name": "Arcane Reveries", "logo": { "@type": "ImageObject", "url": "http://localhost:4000/favicon.png" } }, "author": { "@type": "Person", "name": "M Reddy", "sameAs": [ "" ] }, "description": "Do images speak?" } </script><body class="index-page"><nav class="navbar navbar-transparent navbar-fixed-top navbar-color-on-scroll"><div class="container"><div class="navbar-header"> <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navigation-index"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a href="http://localhost:4000/"><div class="logo-container" style="padding-left: 12px"><div class="logo"> <img src="http://localhost:4000/assets/img/logo.jpg" alt="Manikanta Reddy D" rel="tooltip" title="Hello! Its Me." data-placement="bottom" data-html="true"></div><div class="logo-brand"> Confabs</div></div></a></div><div class="collapse navbar-collapse" id="navigation-index"><ul class="nav navbar-nav navbar-right"><li> <a href="http://localhost:4000/about"> <i class="material-icons">account_circle</i> About </a><li> <a href="http://localhost:4000/blog"> <i class="material-icons">dashboard</i> Posts </a><li> <a href="http://localhost:4000/tags"> <i class="fa fa-tag"></i> Tags </a></ul></div></div></nav><div class="wrapper"><div class="header header-filter" ><div class="container" style=" background-image: url('http://localhost:4000/assets/img/blog.jpg'); width:100%; background-position: center; " ><div class="row" style=" background: rgba(39,62,84,0.82); overflow: hidden; height: 100%; z-index: 500; " ><div class="col-md-8 col-md-offset-2"><div class="brand"><h1>Visual Word Representation</h1><h3></h3></div></div></div></div></div><div class="main"><div class="section"><div class="container"><div class="col-md-10 col-lg-offset-1" style="font-family: 'Comfortaa'"><blockquote><p>Do images speak?</blockquote><div class="row"><p class="col-md-6">08 March 2016<p class="col-md-6">Reading time ~2 minutes</div><div style="overflow: hidden;"><div class="tags" style="white-space: nowrap; overflow-x: auto; overflow-y:hidden; width: 100%; height: 50px"> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/visual-words" class="">visual-words</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/sift" class="">sift</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/image-processing" class="">image-processing</a></button></div></div><hr /><h1 id="visual-word-representation">Visual Word Representation</h1><h2 id="introduction">Introduction</h2><p>Bag of words model of language seems to be very good at matching documents by treating documents as just a bag of important keywords and then matching similar bags! So why not try this on images.<p>After all an image is just a collection of objects! Somehow if we are able to represent these images as a bag of visual words, we might be in luck.<h2 id="visual-word-representation-1">Visual Word Representation</h2><p>The main idea is to arrive at some descriptors called Visual Words. What should visual word look like. It must be a set of lookalike interest points. If we bring similar interest points together they might represent something<p>Now we need to cluster the interest points. Turns out a simple k means clustering is enough. We perform a hierarchical K-Means clustering to some predefined k and depth. The leaf nodes are then believed to be the Visual Words. Now we describe the Image only in terms of the Visual Words.<ul><li>Get SIFT descriptors of Interest points.<li>Perform a Hierarchical K Means, retaining only the centroid for each node.<li>For any image get its SIFT descriptors and for evry descriptor make it travel down the tree, by using a distance measure between the SIFT descriptor and the Node representative.<li>Note the leaf to which it falls. By this way we get a histogram representation of the image in terms of Visual Words.<li>Note the Histogram.</ul><h2 id="implementation">Implementation</h2><p>We’ll be working on the UKY data set which contains about 10,000 images of groups of 4 images. There could be as many as 2000-3000 SIFT interest points in each image.<p>But we’ll be using only 500 feature points on only 1000 images at max to save on memory and computation. Using these 500 SIFT descriptors for every image we performed a normal distance based measurement to find 4 closest neighbors of it using the Vocabulary tree.<p>As the test set and train set are the same, the best match is always the image itself (makes sense) We’ll assign a score of 0.25 if the match lies in one of the four images of the group to which the original image belonged to.<p>At max every image gets a max score of 1 if all the matches belong to the image group, the minimum it gets is 0.25 (A match with itself)<h2 id="results">Results</h2><p><img src="https://raw.githubusercontent.com/manikantareddyd/VisualWordRepresentation/master/res/1.PNG" /><p><img src="https://raw.githubusercontent.com/manikantareddyd/VisualWordRepresentation/master/res/2.PNG" /><p><img src="https://raw.githubusercontent.com/manikantareddyd/VisualWordRepresentation/master/res/3.PNG" /><p>As can be seen it appears that increasing the depth as well as the Number of branches increase the accuracy of match.<p>The accuracies are also very great (~0.98).<p>Using too many images tends to lower the accuracy as the number of available features is too diverse and finding a match becomes difficult.<p>Same is the case with too less features as the data tends to over fit over the given images.<p>The UKY data set can be downloaded from <a href="https://archive.org/details/ukbench" target="_blank"> Here</a><h2> Fork the code</h2><p><a href="https://github.com/ManikantaReddyD/VisualWordRepresentation" target="_blank"><i class="fa fa-3x fa-github"></i></a><hr /><div class="row comments animated fadeInUp"><h3>Comments</h3><button id="show-comments" class="btn btn-primary">Load comments</button><div id="comments-spinner" style="display: none;"><!--<div class="spinner"><div class="rect1"></div><div class="rect2"></div><div class="rect3"></div><div class="rect4"></div><div class="rect5"></div></div>--><div style="text-align: center;"> <svg width="33%" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid" class="lds-infinity"><path fill="none" ng-attr-stroke="" ng-attr-stroke-width="" ng-attr-stroke-dasharray="" d="M24.3,30C11.4,30,5,43.3,5,50s6.4,20,19.3,20c19.3,0,32.1-40,51.4-40 C88.6,30,95,43.3,95,50s-6.4,20-19.3,20C56.4,70,43.6,30,24.3,30z" stroke="#03a9f4" stroke-width="1" stroke-dasharray="6.414723205566406 6.414723205566406"> <animate attributeName="stroke-dashoffset" calcMode="linear" values="0;256.58892822265625" keyTimes="0;1" dur="5" begin="0s" repeatCount="indefinite"></animate> </path> </svg></div></div><div id="comments" style="display: none;"><ul class="nav nav-pills"></ul><hr /><div class="tab-content"></div></div></div><h2 style="text-align: center;">More Posts</h2><div class="row"><div class="col-md-6"><div class="card card-raised"><div class="card-image" style="background-image: url('/assets/posts/2016-04-09-can-we-discriminate/feature.gif'); "></div><div class="content"> <a href="http://localhost:4000/blog/2016/04/09/can-we-discriminate/"><h3>A survey on Human Sex Determination methods</h3></a><div class="row"><p class="col-md-6">09 April 2016<p class="col-md-6">Reading time ~9 minutes</div><p>Identifying the sex of an individual is a challenging problem in Computer Vision. In the recent years various methods have surfaced to solve this classification problem and get closer to achieve be...</div><div class="tags content-bottom"> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/ai" class="">ai</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/machine-learning" class="">machine-learning</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/binary-classification" class="">binary-classification</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/image-processing" class="">image-processing</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/sex" class="">sex</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/feature-engineering" class="">feature-engineering</a></button></div></div></div><div class="col-md-6"><div class="card card-raised"><div class="card-image" style="background-image: url('/assets/posts/2016-02-25-harris-image-match/feature.jpg'); "></div><div class="content"> <a href="http://localhost:4000/blog/2016/02/25/harris-image-match/"><h3>Harris Point Detection and Image Matching</h3></a><div class="row"><p class="col-md-6">25 February 2016<p class="col-md-6">Reading time ~2 minutes</div><p>How well can we compare two images?</div><div class="tags content-bottom"> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/image-processing" class="">image-processing</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/interest-points" class="">interest-points</a></button> <button class="btn btn-simple btn-primary" style="padding: 5px;"><a href="http://localhost:4000/tags/feature-descriptors" class="">feature-descriptors</a></button></div></div></div></div></div></div></div></div></div><!-- Core JS Files --> <script src="http://localhost:4000/assets/javascripts/vendors/jquery.min.js" type="text/javascript"></script> <script src="http://localhost:4000/assets/javascripts/vendors/material-kit/bootstrap.min.js" type="text/javascript"></script> <script src="http://localhost:4000/assets/javascripts/vendors/material-kit/material.min.js"></script><!-- <script src="http://localhost:4000/assets/javascripts/vendors/material-kit/nouislider.min.js" type="text/javascript"></script> --> <script src="http://localhost:4000/assets/javascripts/vendors/material-kit/bootstrap-datepicker.js" type="text/javascript"></script> <script src="http://localhost:4000/assets/javascripts/vendors/material-kit/material-kit.js" type="text/javascript"></script><!-- <script type="text/javascript"> $().ready(function () { materialKit.initSliders(); window_width = $(window).width(); if (window_width >= 992) { big_image = $('.wrapper > .header'); $(window).on('scroll', materialKitDemo.checkScrollForParallax); } }); </script> --><div id="fb-root"></div><script> var load_facebook = function(){ (function (d, s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js = d.createElement(s); js.id = id; js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.5&appId="; fjs.parentNode.insertBefore(js, fjs); }(document, 'script', 'facebook-jssdk')); }; </script> <script src="http://localhost:4000/assets/javascripts/comments.js"></script> <script> $(document).on('click', 'a[href^="#"]', function (event) { event.preventDefault(); $('html, body').animate({ scrollTop: $($.attr(this, 'href')).offset().top -150 }, 500); }); </script>
    