---
layout: post
title: "Unsupervised Learning of Manifolds"
date: 2016-01-26
excerpt: "We will learn the structure of space for a mobile robot, based on observations (i.e. images from the robot's camera) and nothing else.  We will be using the isomap algorithm to discover the lower dimensional manifold embedded in the hyper dimensional space of the image pixels generated by the image simulator."
comments: true
tags: manifolds sklearn simulation uma-thurman bill ai machine-learning
feature: "/assets/posts/2016-01-26-manifold-learning/feature.png"
---



<p>
Meet Bill, the one who has taken over the internet. If you’ve logged on to Facebook at some point in the past week or so, you’ve probably seen a bunch of your friends sharing images Bill. Bill, you see, has perfect etiquette. He doesn’t brag about having a girlfriend every day, he doesn’t tell everyone it’s snowing when it’s obviously snowing, and doesn’t get into heated debates with trolls. He wants everyone to be like him.
</p>
<h3>He had to be stopped
</h3>


<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/bill.jpg" width="40%" />






<p>
Meet Uma Thurman, the one who killed Bill (In KillBill), a robot free to move in an arena bounded by the walls, with an ability to rotate freely about any point.
</p>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/robot.png" >


<p>Walls</p>
<br>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/color.png" width="200px" height="15px">
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/texture.png" width="200px" height="15px">


<p>Arena</p>
<br>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/arena.png" width="40%">



<p>
Uma Thurman is in a square shaped arena with walls having a color gradient or just plain color have been used. The field of view of the robot's camera is 120 degrees. The robot can move anywhere in 'x' and 'y' directions within the arena and rotate about its own axis. The size of the robot itself has been accounted for (by keeping sufficient distance from the walls of the arena).
</p>
<p>
Now we are able to generate images of what Uma Thurman <i>see's</i>.
The images are of size 600x30 RGB. So a given image can be parameterized in 600x30x3 coordinates. An entire rotation about a single point is done in 500 steps( As we'll see taking large number of images doesn't make any significant changes except for consuming more compuation power of the machine.
<br>
We then find the hidden manifold  in the data with the help of the Isomap Algorithm, (a processor hungry beast). The implementation of the manifold isomap algorithm is present in the python scikit libraries and is capable of generating coordinates in the reduced space of the hyper space.
</p>
<pre>
NOTE: The lower dimensional coordinates have no physical significance in this case.
The coordinates are just parameters to represent the images in a lower dimensional space.
By looking at the manifold generated by these lower dimensional coordinates, we are able to infer something about the actual motion of the object.
</pre>

<!-- /container -->



<h2>Rotation about a single Point in arena</h2>

<p>Uma was at (0,0) and then performed a complete rotation about the point.</p>




<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/Plot_0_0_XY.png" width="40%">


<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/Plot_0_0_YZ.png" width="40%">



<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/Plot_0_0_ZX.png" width="40%">


<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/Plot_0_0_All.png" width="40%">


<p>
The first three images are of projections of the 3 dimensional manifold onto 2 dimensional planes. The last one is the manifold itself.
</p>
<ul>
<li>
The first thing that we notice is that the manifold is closed, which gives us an idea that the way the images taken must be repetetive that is the first and last images might be the same, (Which is actual the case)
</li>
<li>
The plot of the first 2 Dimensional Manifold (The first plot) is a circle sugeesting the circular characteristics of data (# The rotation of the robot)
</li>
</ul>

<p>This is the plot for reconstruction error for various number of components in lower dimensional space</p>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/rec_error_1p.png" width="40%">
<p>This suggests that there are only 2 parameters that govern Uma when it rotates about a single point, (An intuition tells that they are x,y)</p>




<h2>3 Points in space</h2>
<p>
Uma Thurman now decided to sit on 3 points and see around, his manifold was similiar but with some weird projections
</p>


<img class="centered" src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/3points-test2.png" width="40%">




<p> Uma got a bit high and decided to take smaller images of width 1px LOL! and this is what it got, it went mad and decided to take images only at 30px width</p>
<p>Although she later deduced that those 3 orthogonal circles in the lower dimensional manifold were representing the 3 points of his choice</p>



<img class="centered" src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/3points-test.png" width="40%">
<p>Till date, Uma is unable to comprehend what it is, that image height did to him, she made a guess that the repetetive pattern in the hyper dimensional coordinates, which she generated by just tailing the rows, which lead to loss of 2 dimensional structuring of image is the culprit</p>



<p>This is the plot for reconstruction error for various number of components in lower dimensional space</p>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/rec_error_3p.png" width="40%">
<p>The older intuiton that x,ywere the parameters when the robot rotates fully is still valid, as the data set is now generated over 3 points, i,e. 6 independent coordinates. This is supported by the reconstruction error plot for 4 distinct points in arena</p>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/rec_error_4p.png" width="40%">
<p>Clearly for 4 points 7-8 dimensions are able to reduce error</p>






<h2>A Random Walk in the arena</h2>
<p>
Now Uma Thurman decided to hop to random points in space, look in some direction and click a picture. This also generated the same type of characteristics as was happeneing in the single point rotation case
</p>


<img class="centered" src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/random_walk.png" width="40%">

<p>
All was well and good, she thought let me hop to 100 random locations and look in all direction (take 100 pictures each time) and deduce something, the result was that she could still see that chair structure with a very stron response.
</p>

<img class="centered" src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/random_walk2.png" width="40%">


<p>Reconstruction error for random walk</p>
<img class="centered" src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/rec_error_rnd.png" width="40%">
<p>The prescence of only two parameters in a total random walk baffeled Uma, this might be because in random walk neighther x nor y nor theta decide the motions, it is the constrained space of the arena that decided how she would move. So may be these two parameters represent the box in which the robot is able to move. By doing this for a really large number of times, she will discover the coordinate system that determines the arena.</p>





<h2>Restimation Error</h2>
<p>
Uma tried to estimate a points orignal coordinates from the coordinates she found in the reduced space. She did this by finding the k nearest neighbours of this point in the Reduced Space and took the mean coordinates of the k neighbours in arena space. These can be generated using the code (refer Coloured Walls/Part3/error.py)
</p>
<p>
She then estimated by how much she was off from the original point and did this for several iteration and found that on an average she was off by 119.69716 units in coodinate and 124.164036883 in theta (she was sceptic about his computation of mean error in theta, as she didn't loop back values after 360)
</p>



<h2>Meet Uma</h2>
<img src="{{ site.url }}/assets/posts/2016-01-26-manifold-learning/img/uma.jpg" width="40%">



<div class="col-lg-12">
<h2>
Questions!
</h2>
<ul>
<li>
<h3>Is it necessary to have gradient or texture on the walls?</h3>
<p>
If the walls had no contrasting features, all images would be identical. So All images lie on same point, in the lower dimensional manifold space, which wouldn't make any sense.
</p>
</li>
<li>
<h3>What happens if instead of theta we had one more linear coordinate?</h3>
<p>
We expect a 3D manifold unlike the 2d manifold we generated in our case. That must be interesting!
</p>
</li>
<li>
<h3>What might be the limitations of such an approach in space discovery?</h3>
<p>
Memory and Computation power!
</p>
<p>
Isomap performs calculations on matrices of order n^k in order n^k times, though polynomial, the datasets involved are real large.
</p>
</li>
</ul>
<center>
<h2> Fork the code </h2>

<a href="https://github.com/ManikantaReddyD/Unsupervised-Learning-Manifolds" target="_blank"><i class="fa fa-3x fa-github"></i></a>
</center>